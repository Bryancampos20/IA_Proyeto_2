{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 1: Importaciones y carga de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wg7sdlzs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f3428387a646c0b5fb2f71b501f8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Model_A_Bilateral_Filter_train_accuracy</td><td>▁█▇</td></tr><tr><td>Model_A_Bilateral_Filter_train_loss</td><td>█▂▄▂▃▂▂▁▁▁▃▃▃</td></tr><tr><td>Model_A_Bilateral_Filter_val_accuracy</td><td>▅▅▁▇▅▃███▄▅▆▇</td></tr><tr><td>Model_A_Bilateral_Filter_val_loss</td><td>▃▂█▁▂▂▁▁▁▂▃▂▁</td></tr><tr><td>Model_A_Canny_Edge_train_accuracy</td><td>▁█▅</td></tr><tr><td>Model_A_Canny_Edge_train_loss</td><td>█▃▂▂▁▁▁▁▁▁▃▂▂</td></tr><tr><td>Model_A_Canny_Edge_val_accuracy</td><td>█▇▃▁▇▆▇▅▄▁█▁▂</td></tr><tr><td>Model_A_Canny_Edge_val_loss</td><td>▅▃▂▃▁▁▁▁▁▂▃█▂</td></tr><tr><td>Model_A_Raw_Data_train_accuracy</td><td>▁▆▇█</td></tr><tr><td>Model_A_Raw_Data_train_loss</td><td>█▂▄▂▂▂▁▁▁▁▆▄▃▂</td></tr><tr><td>Model_A_Raw_Data_val_accuracy</td><td>▃▃▁▅▂▄▆▆█▃▄▅▆▄</td></tr><tr><td>Model_A_Raw_Data_val_loss</td><td>▆█▃▁▂▁▁▁▁▂▂▃▁▂</td></tr><tr><td>Model_B_Bilateral_Filter_train_accuracy</td><td>▁▆█</td></tr><tr><td>Model_B_Bilateral_Filter_train_loss</td><td>█▅▃▃▂▁▁▂▂▁█▅▃</td></tr><tr><td>Model_B_Bilateral_Filter_val_accuracy</td><td>▂▃▃▅█▆▇▆▆▇▁▄▃</td></tr><tr><td>Model_B_Bilateral_Filter_val_loss</td><td>▄▄▄▂▁▂▁▂▁▁▄▄█</td></tr><tr><td>Model_B_Canny_Edge_train_accuracy</td><td>▁█</td></tr><tr><td>Model_B_Canny_Edge_train_loss</td><td>▇▅▅▄▂▁▃▄▄▃█▄</td></tr><tr><td>Model_B_Canny_Edge_val_accuracy</td><td>▃▅▅▅█▃▆▅▅▅▁▂</td></tr><tr><td>Model_B_Canny_Edge_val_loss</td><td>▂▂▂▂▁█▂▄▂▃▃▄</td></tr><tr><td>Model_B_Raw_Data_train_accuracy</td><td>▁▆█</td></tr><tr><td>Model_B_Raw_Data_train_loss</td><td>▇▅▂▂▁▁▁▂▂▁█▄▂</td></tr><tr><td>Model_B_Raw_Data_val_accuracy</td><td>▅▄▃▆██▆▇▆▇▁▂▂</td></tr><tr><td>Model_B_Raw_Data_val_loss</td><td>▄▄▄▂▁▁▂▁▃▁▄▅█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇██▁▁▁▁▁▂▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Model_A_Bilateral_Filter_train_accuracy</td><td>0.95618</td></tr><tr><td>Model_A_Bilateral_Filter_train_loss</td><td>0.13856</td></tr><tr><td>Model_A_Bilateral_Filter_val_accuracy</td><td>0.81818</td></tr><tr><td>Model_A_Bilateral_Filter_val_loss</td><td>0.31944</td></tr><tr><td>Model_A_Canny_Edge_train_accuracy</td><td>0.77291</td></tr><tr><td>Model_A_Canny_Edge_train_loss</td><td>0.67005</td></tr><tr><td>Model_A_Canny_Edge_val_accuracy</td><td>0.33333</td></tr><tr><td>Model_A_Canny_Edge_val_loss</td><td>1.9773</td></tr><tr><td>Model_A_Raw_Data_train_accuracy</td><td>0.94024</td></tr><tr><td>Model_A_Raw_Data_train_loss</td><td>0.18292</td></tr><tr><td>Model_A_Raw_Data_val_accuracy</td><td>0.59091</td></tr><tr><td>Model_A_Raw_Data_val_loss</td><td>1.34015</td></tr><tr><td>Model_B_Bilateral_Filter_train_accuracy</td><td>0.89641</td></tr><tr><td>Model_B_Bilateral_Filter_train_loss</td><td>0.26128</td></tr><tr><td>Model_B_Bilateral_Filter_val_accuracy</td><td>0.51515</td></tr><tr><td>Model_B_Bilateral_Filter_val_loss</td><td>2.27984</td></tr><tr><td>Model_B_Canny_Edge_train_accuracy</td><td>0.55378</td></tr><tr><td>Model_B_Canny_Edge_train_loss</td><td>0.93709</td></tr><tr><td>Model_B_Canny_Edge_val_accuracy</td><td>0.45455</td></tr><tr><td>Model_B_Canny_Edge_val_loss</td><td>1.89858</td></tr><tr><td>Model_B_Raw_Data_train_accuracy</td><td>0.87251</td></tr><tr><td>Model_B_Raw_Data_train_loss</td><td>0.30152</td></tr><tr><td>Model_B_Raw_Data_val_accuracy</td><td>0.48485</td></tr><tr><td>Model_B_Raw_Data_val_loss</td><td>2.1644</td></tr><tr><td>epoch</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comparison_run_modelA_modelB</strong> at: <a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/wg7sdlzs' target=\"_blank\">https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/wg7sdlzs</a><br/> View project at: <a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison' target=\"_blank\">https://wandb.ai/miguelsanchez712000-itcr/model_comparison</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241020_212957-wg7sdlzs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wg7sdlzs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/miguel/Desktop/IA_Proyeto_2/wandb/run-20241020_230905-fzp1wz5t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/fzp1wz5t' target=\"_blank\">comparison_run_modelA_modelB</a></strong> to <a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison' target=\"_blank\">https://wandb.ai/miguelsanchez712000-itcr/model_comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/fzp1wz5t' target=\"_blank\">https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/fzp1wz5t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/miguelsanchez712000-itcr/model_comparison/runs/fzp1wz5t?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7674a1b733d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importaciones y configuración inicial\n",
    "import os\n",
    "import cv2\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler\n",
    "import wandb\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# Usar el backend sin interfaz gráfica\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Cargar las variables de entorno del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Inicialización de WandB\n",
    "wandb.init(\n",
    "    project=\"model_comparison\",\n",
    "    name=\"comparison_run_modelA_modelB\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 64,\n",
    "        \"num_epochs\": 10,\n",
    "        \"architecture_A\": \"ResNet50\",\n",
    "        \"architecture_B\": \"CustomCNN\",\n",
    "        \"dataset\": \"ImageFolder\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 2: Cargar datasets y aplicar transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6023/1496629156.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Obtener las rutas de los datasets desde las variables de entorno\n",
    "train_dataset_path = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "val_dataset_path = os.getenv(\"VAL_DATASET_PATH\")\n",
    "\n",
    "# Verificación de la disponibilidad de GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hiperparámetros\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Transformaciones con Data Augmentation para el conjunto de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformación básica sin Data Augmentation para validación\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar los datasets de imágenes\n",
    "train_raw_dataset = ImageFolder(root=train_dataset_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(root=val_dataset_path, transform=val_transform)\n",
    "\n",
    "train_raw_loader = DataLoader(dataset=train_raw_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 3: Preprocesamiento de imágenes con filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de preprocesamiento de imágenes manteniendo la estructura de clases\n",
    "def copy_images_with_class_structure(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, _ in os.walk(input_dir):\n",
    "        for class_folder in dirs:\n",
    "            class_input_path = os.path.join(input_dir, class_folder)\n",
    "            class_output_path = os.path.join(output_dir, class_folder)\n",
    "            os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "            for file in os.listdir(class_input_path):\n",
    "                if file.endswith(('png', 'jpg', 'jpeg')):\n",
    "                    img_path = os.path.join(class_input_path, file)\n",
    "                    save_path = os.path.join(class_output_path, file)\n",
    "                    cv2.imwrite(save_path, cv2.imread(img_path))\n",
    "\n",
    "def apply_bilateral_filter(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, _ in os.walk(input_dir):\n",
    "        for class_folder in dirs:\n",
    "            class_input_path = os.path.join(input_dir, class_folder)\n",
    "            class_output_path = os.path.join(output_dir, class_folder)\n",
    "            os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "            for file in os.listdir(class_input_path):\n",
    "                if file.endswith(('png', 'jpg', 'jpeg')):\n",
    "                    img_path = os.path.join(class_input_path, file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    filtered_img = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "                    save_path = os.path.join(class_output_path, file)\n",
    "                    cv2.imwrite(save_path, filtered_img)\n",
    "\n",
    "def apply_canny_filter(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, _ in os.walk(input_dir):\n",
    "        for class_folder in dirs:\n",
    "            class_input_path = os.path.join(input_dir, class_folder)\n",
    "            class_output_path = os.path.join(output_dir, class_folder)\n",
    "            os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "            for file in os.listdir(class_input_path):\n",
    "                if file.endswith(('png', 'jpg', 'jpeg')):\n",
    "                    img_path = os.path.join(class_input_path, file)\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    filtered_img = cv2.Canny(img, 100, 200)\n",
    "                    save_path = os.path.join(class_output_path, file)\n",
    "                    cv2.imwrite(save_path, filtered_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 4: Crear loaders para los datasets preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets preprocesados si no existen\n",
    "processed_dir = \"processed_datasets\"\n",
    "raw_data_dir = os.path.join(processed_dir, \"raw\")\n",
    "bilateral_data_dir = os.path.join(processed_dir, \"bilateral\")\n",
    "canny_data_dir = os.path.join(processed_dir, \"canny\")\n",
    "\n",
    "# Aplicar filtros y crear datasets procesados si no existen\n",
    "if not os.path.exists(raw_data_dir):\n",
    "    copy_images_with_class_structure(train_dataset_path, raw_data_dir)\n",
    "\n",
    "if not os.path.exists(bilateral_data_dir):\n",
    "    apply_bilateral_filter(train_dataset_path, bilateral_data_dir)\n",
    "\n",
    "if not os.path.exists(canny_data_dir):\n",
    "    apply_canny_filter(train_dataset_path, canny_data_dir)\n",
    "\n",
    "# Crear datasets preprocesados\n",
    "train_raw_dataset = ImageFolder(root=raw_data_dir, transform=train_transform)\n",
    "train_bilateral_dataset = ImageFolder(root=bilateral_data_dir, transform=train_transform)\n",
    "train_canny_dataset = ImageFolder(root=canny_data_dir, transform=train_transform)\n",
    "\n",
    "# Crear los loaders de los tres conjuntos de datos\n",
    "train_raw_loader = DataLoader(dataset=train_raw_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_bilateral_loader = DataLoader(dataset=train_bilateral_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_canny_loader = DataLoader(dataset=train_canny_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 5: Definir funciones de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Función de entrenamiento con WandB y cálculo de precisión\n",
    "def train(model, train_loader, criterion, optimizer, device, model_name, dataset_name, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        total_samples += labels.size(0)  # Contar muestras para calcular accuracy\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calcular el número de predicciones correctas\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Registrar loss y accuracy en WandB\n",
    "    wandb.log({\n",
    "        f\"{model_name}_{dataset_name}_train_loss\": average_loss,\n",
    "        f\"{model_name}_{dataset_name}_train_accuracy\": accuracy,\n",
    "        'epoch': epoch\n",
    "    })\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "# Función de validación con WandB y matriz de confusión\n",
    "def validate_and_plot_confusion_matrix(model, val_loader, criterion, device, model_name, dataset_name, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct_predictions / len(val_loader.dataset)\n",
    "    average_loss = running_loss / len(val_loader)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"{model_name}_{dataset_name}_val_loss\": average_loss,\n",
    "        f\"{model_name}_{dataset_name}_val_accuracy\": accuracy,\n",
    "        'epoch': epoch\n",
    "    })\n",
    "\n",
    "    # Generar la matriz de confusión\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    # Crear la estructura de carpetas para las matrices de confusión\n",
    "    output_dir = os.path.join(\"confusion_matrices\", model_name, dataset_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Guardar la matriz de confusión en la carpeta correspondiente\n",
    "    file_path = os.path.join(output_dir, f'confusion_matrix_epoch_{epoch}.png')\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Matriz de Confusión - {model_name} - {dataset_name} - Epoch {epoch}')\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "    return average_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 6: Definir Modelo A (ResNet50) y Modelo B (CustomCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA está disponible. Usando GPU.\n",
      "Intentando cargar el modelo A en GPU...\n",
      "Modelo A cargado correctamente en GPU.\n",
      "Intentando cargar el modelo B en GPU...\n",
      "Modelo B cargado correctamente en GPU.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Forzar CUDA_LAUNCH_BLOCKING para una mejor depuración de errores\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Verificar la disponibilidad de CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA está disponible. Usando GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA no está disponible. Usando CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Función para liberar memoria y reiniciar la GPU\n",
    "def liberar_memoria_gpu():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "# Liberar recursos antes de cargar el modelo\n",
    "liberar_memoria_gpu()\n",
    "\n",
    "# Intentar cargar ResNet50 en GPU\n",
    "forzar_gpu = True\n",
    "try:\n",
    "    print(\"Intentando cargar el modelo A en GPU...\")\n",
    "    model_a = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    num_features = model_a.fc.in_features\n",
    "    model_a.fc = nn.Linear(num_features, 3)\n",
    "    if forzar_gpu:\n",
    "        model_a = model_a.to(device)\n",
    "    print(\"Modelo A cargado correctamente en GPU.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error al cargar el Modelo A en GPU: {e}\")\n",
    "    print(\"Liberando recursos de GPU y volviendo a intentar...\")\n",
    "    liberar_memoria_gpu()  # Liberar memoria y volver a intentar en GPU\n",
    "    try:\n",
    "        model_a = model_a.to(device)\n",
    "        print(\"Modelo A cargado correctamente después de liberar GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error persistente al cargar el Modelo A: {e}\")\n",
    "        print(\"Pasando a CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        model_a = model_a.to(device)\n",
    "\n",
    "# Definir la clase CustomCNN antes de usar model_b\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.inception_1x1 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1)\n",
    "        self.inception_3x3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.inception_5x5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(96)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=96, out_channels=128, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=2)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 512)  # Ajuste del tamaño correcto\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x_1x1 = F.relu(self.inception_1x1(x))\n",
    "        x_3x3 = F.relu(self.inception_3x3(x_1x1))\n",
    "        x_5x5 = F.relu(self.inception_5x5(x_1x1))\n",
    "\n",
    "        inception_output = torch.cat([x_1x1, x_3x3, x_5x5], dim=1)\n",
    "        x = self.batch_norm2(inception_output)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Intentar inicializar el modelo B en GPU\n",
    "try:\n",
    "    print(\"Intentando cargar el modelo B en GPU...\")\n",
    "    model_b = CustomCNN(num_classes=3).to(device)\n",
    "    print(\"Modelo B cargado correctamente en GPU.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error al cargar el Modelo B en GPU: {e}\")\n",
    "    print(\"Liberando recursos de GPU y volviendo a intentar...\")\n",
    "    liberar_memoria_gpu()\n",
    "    try:\n",
    "        model_b = model_b.to(device)\n",
    "        print(\"Modelo B cargado correctamente después de liberar GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error persistente al cargar el Modelo B: {e}\")\n",
    "        print(\"Pasando a CPU.\")\n",
    "        model_b = model_b.to(torch.device(\"cpu\"))\n",
    "\n",
    "# Inicialización de los optimizadores\n",
    "optimizer_a = torch.optim.Adam(model_a.parameters(), lr=learning_rate)\n",
    "optimizer_b = torch.optim.Adam(model_b.parameters(), lr=learning_rate)\n",
    "\n",
    "# Liberar memoria de GPU una vez más antes de continuar\n",
    "liberar_memoria_gpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección 7: Entrenamiento y validación de ambos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch [1/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.7353, Train Accuracy: 0.6693, Val Loss: 2.9966, Val Accuracy: 0.4848\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.6134, Train Accuracy: 0.8048, Val Loss: 159.6949, Val Accuracy: 0.4545\n",
      "Modelo A - Canny Edge - Train Loss: 1.9690, Train Accuracy: 0.5976, Val Loss: 59.4218, Val Accuracy: 0.5758\n",
      "Modelo B - Raw Data - Train Loss: 1.1086, Train Accuracy: 0.5020, Val Loss: 1.0738, Val Accuracy: 0.3333\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.6513, Train Accuracy: 0.7171, Val Loss: 1.0160, Val Accuracy: 0.6212\n",
      "Modelo B - Canny Edge - Train Loss: 1.2476, Train Accuracy: 0.4622, Val Loss: 1.0425, Val Accuracy: 0.4848\n",
      "\n",
      "--- Epoch [2/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.2309, Train Accuracy: 0.9004, Val Loss: 1.8946, Val Accuracy: 0.8636\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.2653, Train Accuracy: 0.9004, Val Loss: 0.6461, Val Accuracy: 0.8333\n",
      "Modelo A - Canny Edge - Train Loss: 1.2367, Train Accuracy: 0.6853, Val Loss: 45.2352, Val Accuracy: 0.3939\n",
      "Modelo B - Raw Data - Train Loss: 0.5638, Train Accuracy: 0.7849, Val Loss: 1.3674, Val Accuracy: 0.3939\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.4675, Train Accuracy: 0.7490, Val Loss: 1.2847, Val Accuracy: 0.5000\n",
      "Modelo B - Canny Edge - Train Loss: 1.1396, Train Accuracy: 0.5020, Val Loss: 0.6950, Val Accuracy: 0.6667\n",
      "\n",
      "--- Epoch [3/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.4401, Train Accuracy: 0.8327, Val Loss: 44.1323, Val Accuracy: 0.3939\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.3084, Train Accuracy: 0.8964, Val Loss: 4.9538, Val Accuracy: 0.5303\n",
      "Modelo A - Canny Edge - Train Loss: 0.4912, Train Accuracy: 0.8088, Val Loss: 3.2610, Val Accuracy: 0.4697\n",
      "Modelo B - Raw Data - Train Loss: 0.5581, Train Accuracy: 0.7570, Val Loss: 0.6915, Val Accuracy: 0.6364\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.3231, Train Accuracy: 0.8566, Val Loss: 0.8214, Val Accuracy: 0.7576\n",
      "Modelo B - Canny Edge - Train Loss: 0.9535, Train Accuracy: 0.5697, Val Loss: 1.5008, Val Accuracy: 0.6970\n",
      "\n",
      "--- Epoch [4/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.1565, Train Accuracy: 0.9482, Val Loss: 0.5759, Val Accuracy: 0.6970\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.1172, Train Accuracy: 0.9562, Val Loss: 0.1333, Val Accuracy: 0.8636\n",
      "Modelo A - Canny Edge - Train Loss: 0.3562, Train Accuracy: 0.8845, Val Loss: 0.8560, Val Accuracy: 0.4545\n",
      "Modelo B - Raw Data - Train Loss: 0.3517, Train Accuracy: 0.8406, Val Loss: 0.6682, Val Accuracy: 0.7727\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.2496, Train Accuracy: 0.8845, Val Loss: 0.4922, Val Accuracy: 0.7424\n",
      "Modelo B - Canny Edge - Train Loss: 0.8449, Train Accuracy: 0.5936, Val Loss: 0.5821, Val Accuracy: 0.4697\n",
      "\n",
      "--- Epoch [5/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.0846, Train Accuracy: 0.9721, Val Loss: 0.5318, Val Accuracy: 0.6061\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0624, Train Accuracy: 0.9841, Val Loss: 1.6212, Val Accuracy: 0.7879\n",
      "Modelo A - Canny Edge - Train Loss: 0.3829, Train Accuracy: 0.8367, Val Loss: 1.5143, Val Accuracy: 0.4545\n",
      "Modelo B - Raw Data - Train Loss: 0.2898, Train Accuracy: 0.8924, Val Loss: 0.3890, Val Accuracy: 0.8636\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.2885, Train Accuracy: 0.8884, Val Loss: 0.4985, Val Accuracy: 0.8939\n",
      "Modelo B - Canny Edge - Train Loss: 1.1557, Train Accuracy: 0.5299, Val Loss: 0.4633, Val Accuracy: 0.6970\n",
      "\n",
      "--- Epoch [6/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.0763, Train Accuracy: 0.9761, Val Loss: 4.7519, Val Accuracy: 0.3485\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0750, Train Accuracy: 0.9721, Val Loss: 2.4088, Val Accuracy: 0.5758\n",
      "Modelo A - Canny Edge - Train Loss: 0.4425, Train Accuracy: 0.8446, Val Loss: 0.9889, Val Accuracy: 0.5455\n",
      "Modelo B - Raw Data - Train Loss: 0.2578, Train Accuracy: 0.9004, Val Loss: 0.4028, Val Accuracy: 0.8485\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.2203, Train Accuracy: 0.9203, Val Loss: 0.3246, Val Accuracy: 0.8636\n",
      "Modelo B - Canny Edge - Train Loss: 0.9942, Train Accuracy: 0.4900, Val Loss: 1.4487, Val Accuracy: 0.5152\n",
      "\n",
      "--- Epoch [7/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.1101, Train Accuracy: 0.9681, Val Loss: 0.2169, Val Accuracy: 0.8333\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0739, Train Accuracy: 0.9761, Val Loss: 0.2208, Val Accuracy: 0.9697\n",
      "Modelo A - Canny Edge - Train Loss: 0.4564, Train Accuracy: 0.8327, Val Loss: 7.4949, Val Accuracy: 0.3485\n",
      "Modelo B - Raw Data - Train Loss: 0.2520, Train Accuracy: 0.8924, Val Loss: 0.8369, Val Accuracy: 0.7424\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.1947, Train Accuracy: 0.9243, Val Loss: 0.4995, Val Accuracy: 0.8485\n",
      "Modelo B - Canny Edge - Train Loss: 1.0309, Train Accuracy: 0.5578, Val Loss: 0.2862, Val Accuracy: 0.7879\n",
      "\n",
      "--- Epoch [8/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.1389, Train Accuracy: 0.9522, Val Loss: 1.6250, Val Accuracy: 0.5909\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0891, Train Accuracy: 0.9602, Val Loss: 0.1882, Val Accuracy: 0.8333\n",
      "Modelo A - Canny Edge - Train Loss: 0.3761, Train Accuracy: 0.8845, Val Loss: 0.3516, Val Accuracy: 0.8485\n",
      "Modelo B - Raw Data - Train Loss: 0.2638, Train Accuracy: 0.8884, Val Loss: 0.2600, Val Accuracy: 0.8182\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.2054, Train Accuracy: 0.9323, Val Loss: 0.2876, Val Accuracy: 0.9091\n",
      "Modelo B - Canny Edge - Train Loss: 0.7653, Train Accuracy: 0.6773, Val Loss: 0.3510, Val Accuracy: 0.8485\n",
      "\n",
      "--- Epoch [9/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.0828, Train Accuracy: 0.9801, Val Loss: 0.6065, Val Accuracy: 0.9091\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0853, Train Accuracy: 0.9721, Val Loss: 0.6341, Val Accuracy: 0.9697\n",
      "Modelo A - Canny Edge - Train Loss: 0.2641, Train Accuracy: 0.9243, Val Loss: 0.6264, Val Accuracy: 0.8485\n",
      "Modelo B - Raw Data - Train Loss: 0.1440, Train Accuracy: 0.9442, Val Loss: 0.2673, Val Accuracy: 0.8485\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.1602, Train Accuracy: 0.9442, Val Loss: 0.2662, Val Accuracy: 0.7879\n",
      "Modelo B - Canny Edge - Train Loss: 0.6972, Train Accuracy: 0.6972, Val Loss: 0.3798, Val Accuracy: 0.6970\n",
      "\n",
      "--- Epoch [10/10] ---\n",
      "Modelo A - Raw Data - Train Loss: 0.0339, Train Accuracy: 0.9960, Val Loss: 0.2436, Val Accuracy: 0.9091\n",
      "Modelo A - Bilateral Filter - Train Loss: 0.0301, Train Accuracy: 0.9960, Val Loss: 0.0778, Val Accuracy: 0.9545\n",
      "Modelo A - Canny Edge - Train Loss: 0.1615, Train Accuracy: 0.9482, Val Loss: 0.2040, Val Accuracy: 0.9545\n",
      "Modelo B - Raw Data - Train Loss: 0.1552, Train Accuracy: 0.9402, Val Loss: 0.2001, Val Accuracy: 0.9242\n",
      "Modelo B - Bilateral Filter - Train Loss: 0.1413, Train Accuracy: 0.9442, Val Loss: 0.1266, Val Accuracy: 0.9394\n",
      "Modelo B - Canny Edge - Train Loss: 0.7253, Train Accuracy: 0.6892, Val Loss: 0.3538, Val Accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento y validación para Modelo A y B\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n--- Epoch [{epoch}/{num_epochs}] ---\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset crudo para Modelo A\n",
    "    train_loss, train_accuracy = train(model_a, train_raw_loader, criterion, optimizer_a, device, \"Model_A\", \"Raw_Data\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_a, val_loader, criterion, device, \"Model_A\", \"Raw_Data\", epoch)\n",
    "    print(f\"Modelo A - Raw Data - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset bilateral para Modelo A\n",
    "    train_loss, train_accuracy = train(model_a, train_bilateral_loader, criterion, optimizer_a, device, \"Model_A\", \"Bilateral_Filter\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_a, val_loader, criterion, device, \"Model_A\", \"Bilateral_Filter\", epoch)\n",
    "    print(f\"Modelo A - Bilateral Filter - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset canny para Modelo A\n",
    "    train_loss, train_accuracy = train(model_a, train_canny_loader, criterion, optimizer_a, device, \"Model_A\", \"Canny_Edge\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_a, val_loader, criterion, device, \"Model_A\", \"Canny_Edge\", epoch)\n",
    "    print(f\"Modelo A - Canny Edge - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset crudo para Modelo B\n",
    "    train_loss, train_accuracy = train(model_b, train_raw_loader, criterion, optimizer_b, device, \"Model_B\", \"Raw_Data\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_b, val_loader, criterion, device, \"Model_B\", \"Raw_Data\", epoch)\n",
    "    print(f\"Modelo B - Raw Data - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset bilateral para Modelo B\n",
    "    train_loss, train_accuracy = train(model_b, train_bilateral_loader, criterion, optimizer_b, device, \"Model_B\", \"Bilateral_Filter\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_b, val_loader, criterion, device, \"Model_B\", \"Bilateral_Filter\", epoch)\n",
    "    print(f\"Modelo B - Bilateral Filter - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Entrenamiento y validación en dataset canny para Modelo B\n",
    "    train_loss, train_accuracy = train(model_b, train_canny_loader, criterion, optimizer_b, device, \"Model_B\", \"Canny_Edge\", epoch)\n",
    "    val_loss, val_accuracy = validate_and_plot_confusion_matrix(model_b, val_loader, criterion, device, \"Model_B\", \"Canny_Edge\", epoch)\n",
    "    print(f\"Modelo B - Canny Edge - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
