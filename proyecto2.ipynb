{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11356/3303011272.py:52: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Escalador para precisión mixta\n",
      "/tmp/ipykernel_11356/3303011272.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Usar precisión mixta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo A - Epoch [1/2], Train Loss: 1.0862, Val Loss: 2.3537, Val Accuracy: 0.6061\n",
      "Modelo A - Epoch [2/2], Train Loss: 0.6626, Val Loss: 0.5537, Val Accuracy: 0.7879\n",
      "Modelo B - Epoch [1/2], Train Loss: 0.8866, Val Loss: 0.6599, Val Accuracy: 0.6364\n",
      "Modelo B - Epoch [2/2], Train Loss: 0.6979, Val Loss: 0.5606, Val Accuracy: 0.7727\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cargar las variables de entorno del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las rutas de los datasets desde las variables de entorno\n",
    "train_dataset_path = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "val_dataset_path = os.getenv(\"VAL_DATASET_PATH\")\n",
    "\n",
    "# Verificación de la disponibilidad de GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Modelo A: Cargar ResNet50 preentrenado\n",
    "model_a = models.resnet50(pretrained=True)\n",
    "\n",
    "# Ajustar la última capa para adaptarse a 3 clases\n",
    "num_features = model_a.fc.in_features\n",
    "model_a.fc = nn.Linear(num_features, 3)\n",
    "model_a = model_a.to(device)\n",
    "\n",
    "# Hiperparámetros y configuración de entrenamiento\n",
    "batch_size = 4  # Reducido a 16 para mejorar el uso de memoria\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "\n",
    "# Transformaciones y Aumento de Datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar el Dataset de Imágenes\n",
    "train_dataset = ImageFolder(root=train_dataset_path, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = ImageFolder(root=val_dataset_path, transform=transform)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_a = torch.optim.Adam(model_a.parameters(), lr=learning_rate)\n",
    "scaler = GradScaler()  # Escalador para precisión mixta\n",
    "\n",
    "# Función de entrenamiento con precisión mixta\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():  # Usar precisión mixta\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Liberar memoria después de cada batch\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Función de validación\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Obtener predicciones\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct_predictions / len(val_loader.dataset)\n",
    "    return running_loss / len(val_loader), accuracy\n",
    "\n",
    "# Loop de entrenamiento y validación para Modelo A\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model_a, train_loader, criterion, optimizer_a, device)\n",
    "    val_loss, val_accuracy = validate(model_a, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Modelo A - Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "\n",
    "# Modelo B: Diseño propio de CNN con módulo Inception\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Módulo Inception personalizado\n",
    "        self.inception_1x1 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1)\n",
    "        self.inception_3x3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.inception_5x5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "\n",
    "        # Segunda capa convolucional\n",
    "        self.conv3 = nn.Conv2d(in_channels=96, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Capa totalmente conectada (se inicializa en forward)\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Primera capa convolucional + pooling + dropout\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Módulo inception\n",
    "        x_1x1 = F.relu(self.inception_1x1(x))\n",
    "        x_3x3 = F.relu(self.inception_3x3(x_1x1))\n",
    "        x_5x5 = F.relu(self.inception_5x5(x_1x1))\n",
    "        \n",
    "        # Concatenación de los filtros de inception\n",
    "        inception_output = torch.cat([x_1x1, x_3x3, x_5x5], dim=1)\n",
    "        \n",
    "        # Segunda capa convolucional + pooling + dropout\n",
    "        x = F.relu(self.conv3(inception_output))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Aplanar y ajustar dinámicamente la capa fc1\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Inicialización de fc1 y fc2 en función de la salida aplanada\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.size(1), 512).to(x.device)\n",
    "            self.fc2 = nn.Linear(512, self.num_classes).to(x.device)\n",
    "        \n",
    "        # Pasar por capas totalmente conectadas\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Inicialización del modelo B\n",
    "model_b = CustomCNN(num_classes=3).to(device)\n",
    "optimizer_b = torch.optim.Adam(model_b.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loop de entrenamiento y validación para Modelo B con precisión mixta\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model_b, train_loader, criterion, optimizer_b, device)\n",
    "    val_loss, val_accuracy = validate(model_b, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Modelo B - Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()  # Liberar memoria GPU\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
